{"cells":[{"cell_type":"markdown","source":["## Table batch writes\n- In Databricks Runtime 7.0 and above, SQL also supports a creating table at a path without creating an entry in the Hive metastore.\n- In Databricks Runtime 8.0 and above, Delta Lake is the default format and you don’t need USING DELTA.\n- In Databricks Runtime 7.0 and above, to avoid eventual consistency issues on AWS S3, Databricks recommends using the CREATE OR REPLACE syntax instead of DROP TABLE followed by a CREATE TABLE.\\\n[Documentation here](https://docs.databricks.com/delta/delta-batch.html)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c7de4c6d-1ca5-492b-b10f-1232a891ab0a"}}},{"cell_type":"code","source":["%sql\nCREATE OR REPLACE TABLE default.people10m (\n  id INT,\n  firstName STRING,\n  middleName STRING,\n  lastName STRING,\n  gender STRING,\n  birthDate TIMESTAMP,\n  ssn STRING,\n  salary INT\n) USING DELTA"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3e6c7388-49ef-4f94-8efe-7d352ab1c0c0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#Create table using python\nspark.sql(f\"\"\"\nCREATE TABLE tebleName\nUSING DELTA\nLOCATION \"path/path\" \n\"\"\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"04186fb6-454a-416d-8099-b9734125f415"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Using DataFrameWriter API\n-  If you want to simultaneously create a table and insert data into it from Spark DataFrames or Datasets, you can use the Spark DataFrameWriter with  Python, see the documentation for more options.\n- In Databricks Runtime 8.0 and above, Delta Lake is the default format and you don’t need to specify USING DELTA, format(\"delta\"), or using(\"delta\").\n- In Databricks Runtime 7.0 and above, you can also create Delta tables using the Spark DataFrameWriterV2 API.\\\n[Documentation here](https://docs.databricks.com/delta/delta-batch.html)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f637da9b-b166-4e65-bf34-cc6498cb833a"}}},{"cell_type":"code","source":["## Create table in the metastore using DataFrame's schema and write data to it\n## df.write.format(\"delta\").saveAsTable(\"default.people10m\")\n\n## Create or replace partitioned table with path using DataFrame's schema and write/overwrite data to it\n## df.write.format(\"delta\").mode(\"overwrite\").save(\"/tmp/delta/people10m\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3709405e-77b8-4a8e-84c5-4533351c6158"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#dalete table using python\nspark.sql(f\"\"\"\nDROP TABLE IF EXISTS tebleName\n\"\"\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2d07beec-58c5-4e6c-8530-ecb0918da1c9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"02-Table-Reference","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2678403071749193}},"nbformat":4,"nbformat_minor":0}
